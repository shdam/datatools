{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Web Traffic Analysis\n",
    "**This is the second of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-11-10, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project your task is to analyze a stream of log entries. A log entry consists of an [IP address](https://en.wikipedia.org/wiki/IP_address) and a [domain name](https://en.wikipedia.org/wiki/Domain_name). For example, a log line may look as follows:\n",
    "\n",
    "`192.168.0.1 somedomain.dk`\n",
    "\n",
    "One log line is the result of the event that the domain name was visited by someone having the corresponding IP address. Your task is to analyze the traffic on a number of domains. Counting the number of unique IPs seen on a domain doesn't correspond to the exact number of unique visitors, but it is a good estimate.\n",
    "\n",
    "Specifically, you should answer the following questions from the stream of log entries.\n",
    "\n",
    "- How many unique IPs are there in the stream?\n",
    "- How many unique IPs are there for each domain?\n",
    "- How many times was IP X seen on domain Y? (for some X and Y provided at run time)\n",
    "\n",
    "**The answers to these questions can be approximate!**\n",
    "\n",
    "You should also try to answer one or more of the following, more advanced, questions. The answers to these should also be approximate.\n",
    "\n",
    "- How many unique IPs are there for the domains $d_1, d_2, \\ldots$?\n",
    "- How many times was IP X seen on domains $d_1, d_2, \\ldots$?\n",
    "- What are the X most frequent IPs in the stream?\n",
    "\n",
    "You should use algorithms and data structures that you've learned about in the lectures, and you should provide your own implementations of these.\n",
    "\n",
    "Furthermore, you are expected to:\n",
    "\n",
    "- Document the accuracy of your answers when using algorithms that give approximate answers\n",
    "- Argue why you are using certain parameters for your data structures\n",
    "\n",
    "This notebook is in three parts. In the first part you are given an example of how to read from the stream (which for the purpose of this project is a remote file). In the second part you should implement the algorithms and data structures that you intend to use, and in the last part you should use these for analyzing the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the stream\n",
    "The following code reads a remote file line by line. It is wrapped in a generator to make it easier to extend. You may modify this if you want to, but your solution should remain parametrized, so that your notebook can be run without having to consume the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def stream(n):\n",
    "    i = 0\n",
    "    with urlopen('https://files.dtu.dk/fss/public/link/public/stream/read/traffic_2?linkToken=_DcyO-U3MjjuNzI-&itemName=traffic_2') as f:\n",
    "        for line in f:\n",
    "            element = line.rstrip().decode(\"utf-8\")\n",
    "            yield element\n",
    "            i += 1\n",
    "            if i == n:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREAM_SIZE = 10\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "# list(web_traffic_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of an IP address is 15: ddd.ddd.ddd.ddd.\n",
    "Therefore, according to the Flajolet-Martin Algorithm, a good estimate of required positions in a hash table is 2^15 = 32768.\n",
    "We chose to simply use a 32 bit hash domain, which has 2^32 different values, giving more than enough unique positions, thus more or less eliminating the chance of overlap between input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1302464439"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a 32 bit hash function, the murmurhash3:\n",
    "import mmh3\n",
    "mmh3.hash('186.99.192.116', seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure that all data is processable, we chose to store the data in a database, since a very large data stream could exceed the memory space on our computer.\n",
    "The chosen database structure was tables of each unique domain containing all IP addresses visiting that domain.\n",
    "This structure allowed rapid searches within each domain and required less storage space than simply storing all data.\n",
    "\n",
    "We chose not to store a count for each IP in the domain tables, as this would require a constant search through the database and make creating the database take too much time.\n",
    "\n",
    "To further optimize storage usage, the domains and IPs were hashed in the database to a 32 bit domain.\n",
    "This does introduce some kind of uncertainty, as two IPs could hash to the same value, but with the 2^32 possible values, the risk is minimal.\n",
    "The domain names were hashed in positive values, as SQL does not allow punctuation as table names (except for underscores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove database in case of rerun\n",
    "import os\n",
    "try: os.remove(\"web.db\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('web.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Track unique domain names:\n",
    "domain_names = set()\n",
    "\n",
    "# Function for hashing in seed 42. Domain names are hashed in positive number space.\n",
    "def hash(element, absolute = False):\n",
    "    if absolute:\n",
    "        return abs(mmh3.hash(element, seed = 42))\n",
    "    else:\n",
    "        return mmh3.hash(element, seed = 42)\n",
    "\n",
    "STREAM_SIZE = 10000\n",
    "for element in stream(STREAM_SIZE):\n",
    "    element = element.split('\\t')\n",
    "    IP = hash(element[0])\n",
    "    domain = hash(element[1], True)\n",
    "    domain_names.add(element[1])\n",
    "\n",
    "    add_table = \"\"\"CREATE TABLE IF NOT EXISTS table_{}(id INTEGER PRIMARY KEY, ip REAL)\"\"\".format(domain)\n",
    "    c.execute(add_table)\n",
    "    c.execute('INSERT INTO table_{}(ip) VALUES ({})'.format(domain, IP))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a database has been created capable of answering most questions about the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### How many unique IPs are there in the stream?\n",
    "To answer this question, we collected all distinct IPs from each domain and counted the number of total uniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IPs:\n",
      "9985\n"
     ]
    }
   ],
   "source": [
    "# How many unique IPs are there in the stream?\n",
    "uniques = set()\n",
    "for domain in domain_names:\n",
    "    domain_hash = hash(domain, True)\n",
    "    get_IPs = '''SELECT DISTINCT ip FROM table_{}'''.format(domain_hash)\n",
    "    c.execute(get_IPs)\n",
    "    IPs = c.fetchall()\n",
    "    [uniques.add(IP[0]) for IP in IPs]\n",
    "print('Number of unique IPs:')\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the number of unique IPs are almost as large as the number of elements seen in the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many unique IPs are there for each domain?\n",
    "Here, we looped through the tables and counted the number of distinct IPs for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python.org has 2662 unique IPs\n",
      "pandas.pydata.org has 1323 unique IPs\n",
      "spark.apache.org has 52 unique IPs\n",
      "databricks.com has 130 unique IPs\n",
      "dtu.dk has 273 unique IPs\n",
      "google.com has 256 unique IPs\n",
      "datarobot.com has 14 unique IPs\n",
      "scala-lang.org has 2 unique IPs\n",
      "wikipedia.org has 5154 unique IPs\n",
      "github.com has 134 unique IPs\n"
     ]
    }
   ],
   "source": [
    "# How many unique IPs are there for each domain?\n",
    "for domain in domain_names:\n",
    "    domain_hash = hash(domain, True)\n",
    "    get_IPs = '''SELECT DISTINCT count(ip) FROM table_{}'''.format(domain_hash)\n",
    "    c.execute(get_IPs)\n",
    "    IP_count = c.fetchall()[0][0]\n",
    "    print(domain, 'has', IP_count, 'unique IPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many times was IP X seen on domain Y? (for some X and Y provided at run time)\n",
    "This is answered by looking in the domain table and outputting the count of IPs identical with the input IP_x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times IP_x is seen on domain_y:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# How many times was IP X seen on domain Y? (for some X and Y provided at run time)\n",
    "# Define input variables:\n",
    "IP_x = '186.99.192.116'\n",
    "domain_y = 'python.org'\n",
    "\n",
    "c.execute('SELECT count(ip) FROM table_{} WHERE ip = {}'.format(hash(domain_y, True), hash(IP_x)))\n",
    "print('The number of times IP_x is seen on domain_y:')\n",
    "print(c.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many unique IPs are there for the domains d1,d2,…?\n",
    "The answer to this is found in a much similar way as the similar question answered earlier. The domain names are defined and the corresponding tables are looped through.\n",
    "As before, the count of distinct IPs are printed for each input domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique IPs visiting python.org is:\n",
      "2662\n",
      "The number of unique IPs visiting wikipedia.org is:\n",
      "5154\n",
      "The number of unique IPs visiting pandas.pydata.org is:\n",
      "1323\n",
      "The number of unique IPs visiting github.com is:\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "# How many unique IPs are there for the domains d1,d2,…?\n",
    "ds = ['python.org', 'wikipedia.org', 'pandas.pydata.org', 'github.com']\n",
    "\n",
    "for d in ds:\n",
    "    domain = hash(d, True)\n",
    "    unique_IPs = '''SELECT DISTINCT count(ip) FROM table_{}'''.format(domain)\n",
    "    c.execute(unique_IPs)\n",
    "    print('The number of unique IPs visiting {} is:'.format(d))\n",
    "    print(c.fetchall()[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many times was IP X seen on domains d1,d2,…?\n",
    "Again a list of domains of interest are defined and the tables are looped through, counting the number of times a specific IP occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times IP 186.99.192.116 has visited python.org:\n",
      "1\n",
      "The number of times IP 186.99.192.116 has visited wikipedia.org:\n",
      "0\n",
      "The number of times IP 186.99.192.116 has visited pandas.pydata.org:\n",
      "0\n",
      "The number of times IP 186.99.192.116 has visited github.com:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# How many times was IP X seen on domains d1,d2,…?\n",
    "ds = ['python.org', 'wikipedia.org', 'pandas.pydata.org', 'github.com']\n",
    "IP_x = '186.99.192.116'\n",
    "\n",
    "for d in ds:\n",
    "    domain = hash(d, True)\n",
    "    IP_x_seen = '''SELECT count(ip) FROM table_{}\n",
    "                WHERE ip = {}'''.format(domain, hash(IP_x))\n",
    "    c.execute(IP_x_seen)\n",
    "    print('The number of times IP {} has visited {}:'.format(IP_x, d))\n",
    "    print(c.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the X most frequent IPs in the stream?\n",
    "Noting that the number of unique IPs in the stream is almost as large as the number of stream elements, it will not be possible to do this using a streaming algorithm.\n",
    "Therefore, our best option to solve this is to make a dictionary of all IPs in our datastructure adding a counter to their number of occurances.\n",
    "However, as the IPs were storing in hashes, it is not possible to retreive which hash is which IP, without running through the stream again. Another workaround would have been to store all unique IPs or not hash the IPs when storing them in the database in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1745939879.0, 3), (435711427.0, 3), (2113552735.0, 2), (-510818873.0, 2), (1372869047.0, 2), (1916741674.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "# What are the X most frequent IPs in the stream?\n",
    "X = 5\n",
    "IP_counts = dict()\n",
    "\n",
    "for domain in domain_names:\n",
    "    domain_hash = hash(domain, True)\n",
    "    get_IPs = '''SELECT ip FROM table_{}'''.format(domain_hash)\n",
    "    c.execute(get_IPs)\n",
    "    IPs = c.fetchall()\n",
    "    IPs = [IP[0] for IP in IPs]\n",
    "    for IP in IPs:\n",
    "        if IP in IP_counts:\n",
    "            IP_counts[IP] += 1\n",
    "        else:\n",
    "            IP_counts[IP] = 1\n",
    "\n",
    "sorted_database = sorted(IP_counts.items(), key=lambda item: item[1], reverse = True)\n",
    "print(sorted_database[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
